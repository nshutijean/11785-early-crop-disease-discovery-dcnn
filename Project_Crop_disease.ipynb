{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBITN0M_LKds"
   },
   "source": [
    "# PROJECT: Early crop disease detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdoDIKWOMF59"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dCQlLYldJxX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1668032554081,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "Jza7lwiScUhb",
    "outputId": "f965e3d5-f9aa-47bb-8346-10058aaae256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 11 01:41:50 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.08    Driver Version: 510.73.08    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   25C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi # to see what GPU you have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10250,
     "status": "ok",
     "timestamp": 1668032569148,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "bTxfd_nqFnL9",
    "outputId": "6d6754b4-bf7d-4f24-c09a-0017e74ed2a5"
   },
   "outputs": [],
   "source": [
    "!pip install wandb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5062,
     "status": "ok",
     "timestamp": 1668032574203,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "jwLEd0gdPbSc",
    "outputId": "a1f286ba-1926-4708-f2c9-b8227134bce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "import torchvision #This library is used for image-based operations (Augmentations)\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models  # datsets  , transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from warmup_scheduler import GradualWarmupScheduler\n",
    "import glob\n",
    "import wandb\n",
    "from numba import cuda\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30582,
     "status": "ok",
     "timestamp": 1668032604781,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "SRz9et3SZnbO",
    "outputId": "bd154bdc-8012-4e79-c189-c0a5249b304c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive # Link your drive if you are a colab user\n",
    "# drive.mount('/content/drive') # Models in this HW take a long time to get trained and make sure to save it her"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oxQNl-YVWHc"
   },
   "source": [
    "# TODOs\n",
    "As you go, please read the code and keep an eye out for TODOs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scOnMklwWBY6"
   },
   "source": [
    "# Download Data from Mendley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47260,
     "status": "ok",
     "timestamp": 1668032658995,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "3oFjaJTaRjT7",
    "outputId": "d8fdaed7-3388-4d37-c04c-81bbc7faacfc"
   },
   "outputs": [],
   "source": [
    "!mkdir './content/'\n",
    "!mkdir './content/data'\n",
    "# importing libraries\n",
    "import requests, zipfile, io\n",
    "\n",
    "\"\"\"\n",
    "\tDownload images folder from given url, move it to dataset folder.\n",
    "\"\"\"\n",
    "\n",
    "#url for data without augmentation\n",
    "url = \"https://data.mendeley.com/datasets/tywbtsjrjv/1/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/Plant_leaf_diseases_dataset_without_augmentation.zip?dl=1\"\n",
    "\n",
    "# # url for data with augmentation\n",
    "# url = \"https://data.mendeley.com/datasets/tywbtsjrjv/1/files/b4e3a32f-c0bd-4060-81e9-6144231f2520/Plant_leaf_diseases_dataset_with_augmentation.zip?dl=1\"\n",
    "response = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O68hT27SXClj"
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S7qpMxG0XCJz"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 4, # Increase this if your GPU can handle it\n",
    "    'lr': 0.001,\n",
    "    'checkpointPath' : 'checkpointdiseasef.pth',\n",
    "    'epochs': 10, # 10 epochs is recommended ONLY for the early submission - you will have to train for much longer typically.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSeiKHYrM-6b"
   },
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2YvWtVSEcvWf"
   },
   "outputs": [],
   "source": [
    "transforms = {\n",
    "    'train': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomResizedCrop(224),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(256),\n",
    "        torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(256),\n",
    "        torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = 'Plant_leave_diseases_dataset_without_augmentation'\n",
    "image_datasets = {x: datasets.ImageFolder(data_dir, transform=transforms[x])\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val', 'test']}\n",
    "data_size = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SqSR063BGE2e"
   },
   "outputs": [],
   "source": [
    "# You can do this with ImageFolder as well, but it requires some tweaking\n",
    "class ClassificationTestDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, transforms):\n",
    "        self.data_dir   = data_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # This one-liner basically generates a sorted list of full paths to each image in the test directory\n",
    "        self.img_paths  = list(map(lambda fname: os.path.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transforms(Image.open(self.img_paths[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIqmojPaWD0H"
   },
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1668033250295,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "TkbG05UE7eu8",
    "outputId": "e92b0a50-e95a-43b0-da54-dbacf8816cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]             896\n",
      "              ReLU-2         [-1, 32, 224, 224]               0\n",
      "       BatchNorm2d-3         [-1, 32, 224, 224]              64\n",
      "            Conv2d-4         [-1, 32, 224, 224]           9,248\n",
      "              ReLU-5         [-1, 32, 224, 224]               0\n",
      "       BatchNorm2d-6         [-1, 32, 224, 224]              64\n",
      "         MaxPool2d-7         [-1, 32, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          18,496\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "      BatchNorm2d-10         [-1, 64, 112, 112]             128\n",
      "           Conv2d-11         [-1, 64, 112, 112]          36,928\n",
      "             ReLU-12         [-1, 64, 112, 112]               0\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "        MaxPool2d-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15          [-1, 128, 56, 56]          73,856\n",
      "             ReLU-16          [-1, 128, 56, 56]               0\n",
      "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
      "           Conv2d-18          [-1, 128, 56, 56]         147,584\n",
      "             ReLU-19          [-1, 128, 56, 56]               0\n",
      "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
      "        MaxPool2d-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 256, 28, 28]         295,168\n",
      "             ReLU-23          [-1, 256, 28, 28]               0\n",
      "      BatchNorm2d-24          [-1, 256, 28, 28]             512\n",
      "           Conv2d-25          [-1, 256, 28, 28]         590,080\n",
      "             ReLU-26          [-1, 256, 28, 28]               0\n",
      "      BatchNorm2d-27          [-1, 256, 28, 28]             512\n",
      "        MaxPool2d-28          [-1, 256, 14, 14]               0\n",
      "          Dropout-29                [-1, 50176]               0\n",
      "           Linear-30                 [-1, 1024]      51,381,248\n",
      "             ReLU-31                 [-1, 1024]               0\n",
      "          Dropout-32                 [-1, 1024]               0\n",
      "           Linear-33                   [-1, 39]          39,975\n",
      "================================================================\n",
      "Total params: 52,595,399\n",
      "Trainable params: 52,595,399\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 143.96\n",
      "Params size (MB): 200.64\n",
      "Estimated Total Size (MB): 345.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            # conv1\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            # conv2\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            # conv3\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            # conv4\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.dense_layers = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.4),\n",
    "            torch.nn.Linear(50176, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.4),\n",
    "            torch.nn.Linear(1024, K),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.conv_layers(X)\n",
    "\n",
    "        # Flatten\n",
    "        out = out.view(-1, 50176)\n",
    "\n",
    "        # Fully connected\n",
    "        out = self.dense_layers(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "targets_size =39\n",
    "model = CNN(targets_size)\n",
    "model.to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZCn0qHuZRKj"
   },
   "source": [
    "# Setup everything for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UowI9OcUYPjP"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_conv = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzM11HtcboYv"
   },
   "source": [
    "# Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bgSw6iJJavBZ"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler):\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "    batch_bar = tqdm(total=len(dataloaders['train']), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5) \n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for i,(inputs, labels) in enumerate(dataloaders['train']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * running_corrects / (config['batch_size']*(i + 1))),\n",
    "            loss=\"{:.04f}\".format(float(running_loss / (i + 1))),\n",
    "            running_corrects=running_corrects,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        \n",
    "        # scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
    "        # scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
    "        # scaler.update() \n",
    "\n",
    "        # TODO? Depending on your choice of scheduler,\n",
    "        # You may want to call some schdulers inside the train function. What are these?\n",
    "      \n",
    "        batch_bar.update() # Update tqdm bar\n",
    "        # clear computation cache\n",
    "        torch.cuda.empty_cache()\n",
    "        # del images\n",
    "        # del labels\n",
    "        # del loss\n",
    "\n",
    "    batch_bar.close() # You need this to close the tqdm bar\n",
    "\n",
    "    # acc = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
    "    # total_loss = float(total_loss / len(dataloader))\n",
    "    epoch_loss = running_loss / data_size['train']\n",
    "    epoch_acc = 100*running_corrects.double() / data_size['train']\n",
    "\n",
    "    return epoch_acc, epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "m5V2UdnpdEoK"
   },
   "outputs": [],
   "source": [
    "def validate(model, criterion, optimizer, scheduler):\n",
    "  \n",
    "    model.eval()\n",
    "    batch_bar = tqdm(total=len(dataloaders['val']), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
    "\n",
    "    # model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for i,(inputs, labels) in enumerate(dataloaders['val']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # if phase == 'train':\n",
    "    # scheduler.step()\n",
    "                \n",
    "    # epoch_loss = running_loss / data_size['train']\n",
    "    # epoch_acc = 100*running_corrects.double() / data_size['train']\n",
    "            \n",
    "            # print('{} Loss: {:.4f} Train Acc: {:.4f}'.format(\n",
    "            #     phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # tqdm lets you add some details so you can monitor training as you train.\n",
    "        batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * running_corrects / (config['batch_size']*(i + 1))),\n",
    "            loss=\"{:.04f}\".format(float(running_loss / (i + 1))),\n",
    "            running_corrects=running_corrects,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "        \n",
    "        # scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
    "        # scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
    "        # scaler.update() \n",
    "\n",
    "        # TODO? Depending on your choice of scheduler,\n",
    "        # You may want to call some schdulers inside the train function. What are these?\n",
    "      \n",
    "        batch_bar.update() # Update tqdm bar\n",
    "        # clear computation cache\n",
    "        torch.cuda.empty_cache()\n",
    "        # del images\n",
    "        # del labels\n",
    "        # del loss\n",
    "\n",
    "    batch_bar.close() # You need this to close the tqdm bar\n",
    "\n",
    "    # acc = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
    "    # total_loss = float(total_loss / len(dataloader))\n",
    "    epoch_loss = running_loss / data_size['val']\n",
    "    epoch_acc = 100*running_corrects.double() / data_size['val']\n",
    "\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LccUHgcoe56O"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                batch_bar = tqdm(total=len(dataloaders['train']), dynamic_ncols=True, position=0, leave=False, desc='Train', ncols=5)\n",
    "            else:\n",
    "                model.eval()\n",
    "                batch_bar = tqdm(total=len(dataloaders['val']), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for i,(inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / data_size[phase]\n",
    "            epoch_acc = running_corrects.double() / data_size[phase]\n",
    "            \n",
    "            batch_bar.set_postfix(\n",
    "            acc=\"{:.04f}%\".format(100 * running_corrects / (config['batch_size']*(i + 1))),\n",
    "            loss=\"{:.04f}\".format(float(running_loss / (i + 1))),\n",
    "            running_corrects=running_corrects,\n",
    "            lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "            \n",
    "#             print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(val_acc, val_loss))\n",
    "\n",
    "            wandb.log({\"train_loss\":epoch_loss, 'train_Acc': epoch_acc})\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 val_=epoch_acc\n",
    "                best_acc = epoch_acc\n",
    "                \n",
    "                # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print(\"Saving model\")\n",
    "                torch.save({'model_state_dict':model.state_dict(),\n",
    "                            'optimizer_state_dict':optimizer_conv.state_dict(),\n",
    "                            #'scheduler_state_dict':scheduler.state_dict(),\n",
    "                            'epoch_acc': epoch_acc, \n",
    "                            'epoch': epoch}, './checkpointdiseasef.pth')\n",
    "                # best_valacc = val_acc\n",
    "                wandb.save('checkpointdiseasef.pth')\n",
    "                \n",
    "#             print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(epoch_acc, val_loss))\n",
    "            if phase=='val':\n",
    "                wandb.log({'validation_Acc':epoch_acc, \n",
    "                   'validation_loss': epoch_loss})\n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "h1Mt1VD-frLF"
   },
   "outputs": [],
   "source": [
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer_conv = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cmotca6pcLLY"
   },
   "outputs": [],
   "source": [
    "gc.collect() # These commands help you when you face CUDA OOM error\n",
    "torch.cuda.empty_cache()\n",
    "# free_gpu_cache()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mBgKGkXLrdJ"
   },
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1668033258388,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "Ix62_BkaLr_D",
    "outputId": "4b513d3e-4fb0-4913-ef43-a0011eda3cbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msntivugu\u001b[0m (\u001b[33mruffers\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"0df4b2e8d09c7bfafcc61974b29dd9ab7ed479b6\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "55c2efbd546747889a9216fa99bfbf7f",
      "e241a0267cbc45e1a70fb339a14a0891",
      "eb849aeb75e3448da504e1e1e65b2dde",
      "4633e9119a1241198efe117aeb39e1f4",
      "a788bcc682144491b1eb29a4a29b705b",
      "1a2731f6ae4d4ac2af8e99edce7a37a9",
      "1d74f30999f5499792179d9bb96a5f1b",
      "09b4dce1c03c435185e8e60cc4de6c0f"
     ]
    },
    "executionInfo": {
     "elapsed": 6457,
     "status": "ok",
     "timestamp": 1668033264833,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "VG0vmsmbRYEi",
    "outputId": "ed4be219-9c07-4d33-8942-b5e146f7a346"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/crop_disease_detection_idl/wandb/run-20221111_014301-1tex8yye</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/ruffers/Crop_disease_midterm/runs/1tex8yye\" target=\"_blank\">Crop_disease_midterm</a></strong> to <a href=\"https://wandb.ai/ruffers/Crop_disease_midterm\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create your wandb run\n",
    "run = wandb.init(\n",
    "    name = \"Crop_disease_midterm\", ## Wandb creates random run names if you skip this field\n",
    "#     reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    id = '1tex8yye', ###Insert specific run id here if you want to resume a previous run\n",
    "    resume = True, ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"Crop_disease_midterm\", ### Project should be created in your wandb account \n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQkRw1FvLqYe"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csVrh81QzzV9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:42<?, ?it/s, acc=88.2791%, loss=1.5055, lr=0.0000, running_corrects=tensor(48949, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3764 Acc: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:30<?, ?it/s, acc=96.6762%, loss=0.5713, lr=0.0000, running_corrects=tensor(53605, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1428 Acc: 0.9668\n",
      "Saving model\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:49<?, ?it/s, acc=88.0609%, loss=1.5045, lr=0.0000, running_corrects=tensor(48828, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3761 Acc: 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:30<?, ?it/s, acc=95.2153%, loss=1.5014, lr=0.0000, running_corrects=tensor(52795, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3754 Acc: 0.9522\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:47<?, ?it/s, acc=88.4522%, loss=1.4693, lr=0.0000, running_corrects=tensor(49045, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3673 Acc: 0.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:30<?, ?it/s, acc=95.8592%, loss=0.9107, lr=0.0000, running_corrects=tensor(53152, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2277 Acc: 0.9586\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:47<?, ?it/s, acc=88.1330%, loss=1.5388, lr=0.0000, running_corrects=tensor(48868, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3847 Acc: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:30<?, ?it/s, acc=96.0251%, loss=0.8433, lr=0.0000, running_corrects=tensor(53244, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2108 Acc: 0.9603\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:46<?, ?it/s, acc=88.4180%, loss=1.4899, lr=0.0000, running_corrects=tensor(49026, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3725 Acc: 0.8842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:30<?, ?it/s, acc=96.4868%, loss=0.6485, lr=0.0000, running_corrects=tensor(53500, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1621 Acc: 0.9649\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:47<?, ?it/s, acc=88.3368%, loss=1.5062, lr=0.0000, running_corrects=tensor(48981, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3765 Acc: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:30<?, ?it/s, acc=96.3443%, loss=0.7428, lr=0.0000, running_corrects=tensor(53421, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1857 Acc: 0.9634\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:47<?, ?it/s, acc=88.0952%, loss=1.5149, lr=0.0000, running_corrects=tensor(48847, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3787 Acc: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:31<?, ?it/s, acc=96.3010%, loss=0.7150, lr=0.0000, running_corrects=tensor(53397, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1787 Acc: 0.9630\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:48<?, ?it/s, acc=88.3855%, loss=1.4881, lr=0.0000, running_corrects=tensor(49008, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3720 Acc: 0.8839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:31<?, ?it/s, acc=95.1107%, loss=1.4311, lr=0.0000, running_corrects=tensor(52737, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3578 Acc: 0.9511\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|                         | 0/13862 [08:48<?, ?it/s, acc=88.1565%, loss=1.5177, lr=0.0000, running_corrects=tensor(48881, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3794 Acc: 0.8816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val:   0%|                           | 0/13862 [02:31<?, ?it/s, acc=95.7293%, loss=1.0440, lr=0.0000, running_corrects=tensor(53080, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2610 Acc: 0.9573\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    }
   ],
   "source": [
    "# free_gpu_cache() \n",
    "\n",
    "model_resnet = train_model(model, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "executionInfo": {
     "elapsed": 1316842,
     "status": "error",
     "timestamp": 1668034581661,
     "user": {
      "displayName": "Sylvan",
      "userId": "10403617381248947394"
     },
     "user_tz": -120
    },
    "id": "EqWO8Edb0BK2",
    "outputId": "53676376-e5f1-4322-d408-d6f097424980"
   },
   "outputs": [],
   "source": [
    "best_valacc = 0.0\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "\n",
    "    curr_lr = float(optimizer_conv.param_groups[0]['lr'])\n",
    "\n",
    "    train_acc, train_loss = train(model, criterion, optimizer_conv, exp_lr_scheduler)\n",
    "    # train_losses, validation_losses = batch_gd(\n",
    "    # model, criterion, train_loader, validation_loader, 5)\n",
    "    \n",
    "    print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n",
    "        epoch + 1,\n",
    "        config['epochs'],\n",
    "        train_acc,\n",
    "        train_loss,\n",
    "        curr_lr))\n",
    "    \n",
    "    val_acc, val_loss = validate(model, criterion, optimizer_conv, exp_lr_scheduler)\n",
    "    \n",
    "    print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(val_acc, val_loss))\n",
    "\n",
    "    wandb.log({\"train_loss\":train_loss, 'train_Acc': train_acc, 'validation_Acc':val_acc, \n",
    "               'validation_loss': val_loss, \"learning_Rate\": curr_lr})\n",
    "    \n",
    "    # If you are using a scheduler in your train function within your iteration loop, you may want to log\n",
    "    # your learning rate differently \n",
    "\n",
    "    # #Save model in drive location if val_acc is better than best recorded val_acc\n",
    "    if val_acc >= best_valacc:\n",
    "      #path = os.path.join(root, model_directory, 'checkpoint' + '.pth')\n",
    "      print(\"Saving model\")\n",
    "      torch.save({'model_state_dict':model.state_dict(),\n",
    "                  'optimizer_state_dict':optimizer_conv.state_dict(),\n",
    "                  #'scheduler_state_dict':scheduler.state_dict(),\n",
    "                  'val_acc': val_acc, \n",
    "                  'epoch': epoch}, './drive/MyDrive/checkpointdiseasefv3.pth')\n",
    "      best_valacc = val_acc\n",
    "      wandb.save('checkpointdiseasefv2.pth')\n",
    "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpgCHImRkYQW"
   },
   "source": [
    "# Classification Task: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7R1lcCAzULc"
   },
   "outputs": [],
   "source": [
    "# test_results = test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09b4dce1c03c435185e8e60cc4de6c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a2731f6ae4d4ac2af8e99edce7a37a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d74f30999f5499792179d9bb96a5f1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4633e9119a1241198efe117aeb39e1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55c2efbd546747889a9216fa99bfbf7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e241a0267cbc45e1a70fb339a14a0891",
       "IPY_MODEL_eb849aeb75e3448da504e1e1e65b2dde"
      ],
      "layout": "IPY_MODEL_4633e9119a1241198efe117aeb39e1f4"
     }
    },
    "a788bcc682144491b1eb29a4a29b705b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e241a0267cbc45e1a70fb339a14a0891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a788bcc682144491b1eb29a4a29b705b",
      "placeholder": "​",
      "style": "IPY_MODEL_1a2731f6ae4d4ac2af8e99edce7a37a9",
      "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "eb849aeb75e3448da504e1e1e65b2dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d74f30999f5499792179d9bb96a5f1b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09b4dce1c03c435185e8e60cc4de6c0f",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
